{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d997198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Toma la API key desde la variable de entorno\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "MEMORY_FILE = \"memoria.json\"\n",
    "PROFILE_FILE = \"perfil_usuario.json\"  \n",
    "# Historial de la conversación proactiva (solo texto)\n",
    "CONVERSACION_PROACTIVA = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326d624",
   "metadata": {},
   "source": [
    "## Perfil de la persona (carga inicial + actualización segun comentarios de la misma persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92d2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfil_por_defecto():\n",
    "    return {\n",
    "        \"nombre\": None,\n",
    "        \"edad\": None,\n",
    "        \"fecha_nacimiento\": None,\n",
    "        \"genero\": None,\n",
    "        \"condiciones_salud\": [],\n",
    "        \"medicamentos_cronicos\": [],\n",
    "        \"preferencias\": {\n",
    "            \"tratamiento\": None,          # \"tuteo\" / \"usted\"\n",
    "            \"temas_favoritos\": [],        # ej: [\"nietos\", \"jardinería\"]\n",
    "            \"tono_respuesta\": None        # ej: \"cálido y paciente\"\n",
    "        },\n",
    "        \"familia\": []                     # lista de {\"nombre\":..,\"relacion\":..}\n",
    "    }\n",
    "\n",
    "def cargar_perfil():\n",
    "    \"\"\"Carga el perfil desde disco o devuelve uno por defecto si no existe.\"\"\"\n",
    "    if not os.path.exists(PROFILE_FILE):\n",
    "        return perfil_por_defecto()\n",
    "    with open(PROFILE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def guardar_perfil(perfil: dict):\n",
    "    \"\"\"Guarda el perfil completo en disco.\"\"\"\n",
    "    with open(PROFILE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(perfil, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfil = cargar_perfil()\n",
    "#perfil[\"nombre\"] = \"María\"\n",
    "#guardar_perfil(perfil)\n",
    "\n",
    "perfil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info_perfil_desde_texto(texto: str) -> dict:\n",
    "    \"\"\"\n",
    "    Usa gpt-4o-mini para ver si el texto contiene información del perfil del usuario.\n",
    "    Devuelve un dict del tipo:\n",
    "    {\n",
    "      \"contiene_info_perfil\": true/false,\n",
    "      \"campos\": {\n",
    "         ... solo los campos que hay que actualizar ...\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    system_msg = \"\"\"\n",
    "Eres un asistente que extrae INFORMACIÓN DE PERFIL de una persona mayor,\n",
    "a partir de lo que dice en voz alta.\n",
    "\n",
    "El perfil tiene esta estructura:\n",
    "\n",
    "{\n",
    "  \"nombre\": string o null,\n",
    "  \"edad\": number o null,\n",
    "  \"fecha_nacimiento\": string (AAAA-MM-DD) o null,\n",
    "  \"genero\": string o null,\n",
    "  \"condiciones_salud\": [string, ...],\n",
    "  \"medicamentos_cronicos\": [string, ...],\n",
    "  \"preferencias\": {\n",
    "    \"tratamiento\": string o null,        // \"tuteo\" o \"usted\" u otra cosa textual\n",
    "    \"temas_favoritos\": [string, ...],\n",
    "    \"tono_respuesta\": string o null\n",
    "  },\n",
    "  \"familia\": [\n",
    "    {\"nombre\": string, \"relacion\": string}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Tu tarea:\n",
    "\n",
    "1. Decidir si el texto contiene información relevante para el perfil.\n",
    "   Ejemplos de información relevante:\n",
    "   - nombre, edad, fecha de nacimiento\n",
    "   - \"tengo diabetes\", \"soy hipertenso\", \"soy alérgica a...\"\n",
    "   - \"tomo metformina todos los días\"\n",
    "   - \"me gusta que me hablen de usted\"\n",
    "   - \"me gusta hablar de mis nietos\"\n",
    "   - \"mi hijo Juan vive en tal parte\"\n",
    "\n",
    "2. Si NO hay información de perfil → responde:\n",
    "   {\"contiene_info_perfil\": false, \"campos\": {}}\n",
    "\n",
    "3. Si SÍ hay información de perfil → responde:\n",
    "   {\n",
    "     \"contiene_info_perfil\": true,\n",
    "     \"campos\": {\n",
    "        ... SOLO los campos que se pueden inferir del texto ...\n",
    "     }\n",
    "   }\n",
    "\n",
    "Reglas importantes:\n",
    "- NO inventes datos que no estén en el texto.\n",
    "- Si mencionan varias condiciones de salud, usa una lista en \"condiciones_salud\".\n",
    "- Si hay nuevos medicamentos crónicos, ponlos en \"medicamentos_cronicos\".\n",
    "- En \"familia\", solo agrega personas si se menciona claramente la relación (hijo, hija, nieto, etc.).\n",
    "- Si no estás seguro de un campo, omítelo.\n",
    "- Devuelve SIEMPRE un JSON válido y NADA más.\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": texto},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw = completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"No se pudo parsear JSON al extraer perfil. Respuesta cruda:\")\n",
    "        print(raw)\n",
    "        raise\n",
    "\n",
    "    # normalizar\n",
    "    if \"contiene_info_perfil\" not in data:\n",
    "        data[\"contiene_info_perfil\"] = False\n",
    "    if \"campos\" not in data:\n",
    "        data[\"campos\"] = {}\n",
    "\n",
    "    return data\n",
    "\n",
    "def merge_preferencias(pref_actual: dict, pref_nuevas: dict) -> dict:\n",
    "    \"\"\"Fusiona el sub-dict de preferencias.\"\"\"\n",
    "    if pref_actual is None:\n",
    "        pref_actual = {\"tratamiento\": None, \"temas_favoritos\": [], \"tono_respuesta\": None}\n",
    "\n",
    "    pref = pref_actual.copy()\n",
    "\n",
    "    if \"tratamiento\" in pref_nuevas and pref_nuevas[\"tratamiento\"] is not None:\n",
    "        pref[\"tratamiento\"] = pref_nuevas[\"tratamiento\"]\n",
    "\n",
    "    if \"tono_respuesta\" in pref_nuevas and pref_nuevas[\"tono_respuesta\"] is not None:\n",
    "        pref[\"tono_respuesta\"] = pref_nuevas[\"tono_respuesta\"]\n",
    "\n",
    "    if \"temas_favoritos\" in pref_nuevas:\n",
    "        # agregamos sin duplicar\n",
    "        actuales = set(pref.get(\"temas_favoritos\") or [])\n",
    "        nuevos = set(pref_nuevas[\"temas_favoritos\"] or [])\n",
    "        pref[\"temas_favoritos\"] = list(actuales.union(nuevos))\n",
    "\n",
    "    return pref\n",
    "\n",
    "def merge_familia(familia_actual: list, familia_nueva: list) -> list:\n",
    "    \"\"\"\n",
    "    Fusiona listas de familia sin duplicar.\n",
    "    Considera duplicado si nombre + relacion coinciden.\n",
    "    \"\"\"\n",
    "    if familia_actual is None:\n",
    "        familia_actual = []\n",
    "    existentes = {(m.get(\"nombre\"), m.get(\"relacion\")) for m in familia_actual}\n",
    "    resultado = list(familia_actual)\n",
    "    for miembro in familia_nueva or []:\n",
    "        key = (miembro.get(\"nombre\"), miembro.get(\"relacion\"))\n",
    "        if key not in existentes:\n",
    "            resultado.append(miembro)\n",
    "            existentes.add(key)\n",
    "    return resultado\n",
    "\n",
    "def actualizar_perfil_con_campos(perfil: dict, campos: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Actualiza el perfil con los campos extraídos del LLM.\n",
    "    Solo pisa / agrega lo que venga en 'campos'.\n",
    "    \"\"\"\n",
    "    p = perfil.copy()\n",
    "\n",
    "    # Campos simples\n",
    "    for k in [\"nombre\", \"edad\", \"fecha_nacimiento\", \"genero\"]:\n",
    "        if k in campos and campos[k] is not None:\n",
    "            p[k] = campos[k]\n",
    "\n",
    "    # Listas: condiciones_salud, medicamentos_cronicos\n",
    "    for k in [\"condiciones_salud\", \"medicamentos_cronicos\"]:\n",
    "        if k in campos:\n",
    "            actuales = set(p.get(k) or [])\n",
    "            nuevos = set(campos[k] or [])\n",
    "            p[k] = list(actuales.union(nuevos))\n",
    "\n",
    "    # Preferencias (sub-dict)\n",
    "    if \"preferencias\" in campos:\n",
    "        p[\"preferencias\"] = merge_preferencias(\n",
    "            p.get(\"preferencias\"),\n",
    "            campos[\"preferencias\"]\n",
    "        )\n",
    "\n",
    "    # Familia (lista de personas)\n",
    "    if \"familia\" in campos:\n",
    "        p[\"familia\"] = merge_familia(\n",
    "            p.get(\"familia\"),\n",
    "            campos[\"familia\"]\n",
    "        )\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bb945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_texto_para_perfil(texto: str) -> dict:\n",
    "    \"\"\"\n",
    "    Dado un texto (por ej. transcripción de audio), detecta si hay info de perfil,\n",
    "    actualiza el perfil en disco y devuelve el perfil actualizado.\n",
    "    \"\"\"\n",
    "    perfil = cargar_perfil()\n",
    "    extraido = extraer_info_perfil_desde_texto(texto)\n",
    "\n",
    "    if not extraido.get(\"contiene_info_perfil\"):\n",
    "        print(\"No se detectó información de perfil en este texto.\")\n",
    "        return perfil\n",
    "\n",
    "    campos = extraido.get(\"campos\", {})\n",
    "    perfil_actualizado = actualizar_perfil_con_campos(perfil, campos)\n",
    "    guardar_perfil(perfil_actualizado)\n",
    "\n",
    "    print(\"Perfil actualizado con:\")\n",
    "    print(json.dumps(campos, ensure_ascii=False, indent=2))\n",
    "\n",
    "    return perfil_actualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ebca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_demo = \"Me llamo Elvira Soto, tengo 79 años, soy diabética y me gusta que me hablen de tú.\"\n",
    "perfil_act = procesar_texto_para_perfil(texto_demo)\n",
    "perfil_act\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cargar_perfil_simple():\n",
    "    \"\"\"\n",
    "    Si ya tienes otra función cargar_perfil(), puedes usarla directamente.\n",
    "    Esta es por si no la tienes centralizada.\n",
    "    \"\"\"\n",
    "    if os.path.exists(PROFILE_FILE):\n",
    "        with open(PROFILE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return {}  # perfil vacío si aún no hay info\n",
    "\n",
    "\n",
    "def construir_contexto_perfil(perfil: dict) -> str:\n",
    "    \"\"\"\n",
    "    Convierte el perfil en un texto corto para el prompt.\n",
    "    No se rompe si faltan campos.\n",
    "    \"\"\"\n",
    "    nombre = perfil.get(\"nombre\") or \"la persona usuaria\"\n",
    "    edad = perfil.get(\"edad\")\n",
    "    genero = perfil.get(\"genero\")\n",
    "    conds = perfil.get(\"condiciones_salud\") or []\n",
    "    meds = perfil.get(\"medicamentos_cronicos\") or []\n",
    "    pref = perfil.get(\"preferencias\") or {}\n",
    "    tratamiento = pref.get(\"tratamiento\")\n",
    "    tono = pref.get(\"tono_respuesta\")\n",
    "    temas_fav = pref.get(\"temas_favoritos\") or []\n",
    "    familia = perfil.get(\"familia\") or []\n",
    "\n",
    "    lineas = []\n",
    "\n",
    "    desc = f\"Nombre: {nombre}.\"\n",
    "    if edad:\n",
    "        desc += f\" Edad: {edad} años.\"\n",
    "    if genero:\n",
    "        desc += f\" Género: {genero}.\"\n",
    "    lineas.append(desc)\n",
    "\n",
    "    if conds:\n",
    "        lineas.append(\"Condiciones de salud conocidas: \" + \", \".join(conds) + \".\")\n",
    "    if meds:\n",
    "        lineas.append(\"Medicamentos crónicos: \" + \", \".join(meds) + \".\")\n",
    "\n",
    "    pref_parts = []\n",
    "    if tratamiento:\n",
    "        pref_parts.append(f\"Prefiere que le hablen de '{tratamiento}'.\")\n",
    "    if tono:\n",
    "        pref_parts.append(f\"Prefiere un tono de respuesta '{tono}'.\")\n",
    "    if temas_fav:\n",
    "        pref_parts.append(\"Le gusta hablar de: \" + \", \".join(temas_fav) + \".\")\n",
    "    if pref_parts:\n",
    "        lineas.append(\"Preferencias de interacción: \" + \" \".join(pref_parts))\n",
    "\n",
    "    if familia:\n",
    "        fam_txt = \"; \".join(\n",
    "            f\"{m.get('nombre')} ({m.get('relacion')})\"\n",
    "            for m in familia\n",
    "            if m.get(\"nombre\") and m.get(\"relacion\")\n",
    "        )\n",
    "        if fam_txt:\n",
    "            lineas.append(\"Personas importantes en su familia: \" + fam_txt + \".\")\n",
    "\n",
    "    return \"\\n\".join(lineas)\n",
    "\n",
    "\n",
    "def construir_system_con_perfil(instrucciones_base: str) -> str:\n",
    "    \"\"\"\n",
    "    Usa el perfil guardado para agregar contexto al system prompt.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        perfil = cargar_perfil_simple()\n",
    "    except Exception:\n",
    "        perfil = {}\n",
    "\n",
    "    contexto = construir_contexto_perfil(perfil)\n",
    "\n",
    "    return (\n",
    "        instrucciones_base.strip()\n",
    "        + \"\\n\\nCONTEXTO DEL USUARIO (importante):\\n\"\n",
    "        + contexto\n",
    "        + \"\\n\\nTen en cuenta este contexto en todas tus decisiones y en el tono de tus respuestas.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813c5f7",
   "metadata": {},
   "source": [
    "## Transcripción audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40913e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(AUDIO_PATH):\n",
    "    with open(AUDIO_PATH, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",   # modelo de transcripción\n",
    "            file=audio_file,\n",
    "            # language=\"es\",      # opcional: forzar español\n",
    "            # temperature=0.0,    # opcional: menos creatividad\n",
    "        )\n",
    "    texto = transcription.text\n",
    "\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "685a3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def procesar_memoria_con_chatgpt(texto: str):\n",
    "    \"\"\"\n",
    "    Dado el texto transcrito de un audio, devuelve una LISTA de objetos, cada uno con la estructura:\n",
    "\n",
    "    {\n",
    "      \"tipo\": \"Evento\" | \"Recuerdo\" | \"Ninguno\",\n",
    "      \"fecha\": str | null,\n",
    "      \"hora\": str | null,\n",
    "      \"descripcion\": str | null,\n",
    "      \"clasificacion\": \"tarea\" | \"compra\" | \"pensamiento\" | \"otro\" | null,\n",
    "      \"responsable_requerido\": \"Si\" | \"No\" | null,\n",
    "      \"personas\": [str, ...],\n",
    "      \"lugar\": str | null\n",
    "    }\n",
    "\n",
    "    Si no hay nada útil, devuelve [].\n",
    "    \"\"\"\n",
    "\n",
    "    base_instructions = \"\"\"\n",
    "    \n",
    "Eres un asistente de MEMORIA para una persona mayor. La idea es que esta persona te use para ir guardando información importante, recuerdos, etc. \n",
    "A veces no va a ser explícita la información, por lo que tienes que lograr interpretar las cosas obvias. Por ejemplo, si dice \"médico de la cabeza\", se\n",
    "refiere al neurólogo. Si te dice \"este lunes tengo algo\", asume que estamos en la fecha del día de hoy, y por ende entrega la fecha del lunes que viene\n",
    "correspondiente. Trata de interpretar solo cuando se pueda, no inventes o uses información que no ha dicho.\n",
    "\n",
    "Vas a recibir el TEXTO de algo que la persona dijo en voz alta.\n",
    "En un MISMO audio puede haber VARIAS ideas distintas:\n",
    "- varios eventos (cumpleaños, citas, salidas)\n",
    "- varios recuerdos o pedidos (comprar algo, llamar a alguien, pensamientos)\n",
    "\n",
    "Tu tarea es:\n",
    "\n",
    "1) LEER TODO el texto y separar cada \"pieza de información\" en ítems independientes.\n",
    "   Por ejemplo, si dice:\n",
    "   \"El jueves es el cumpleaños de mi hija. También tengo que comprar limones.\n",
    "    Y hace mucho que no sé de Juanito Perez, debería llamarlo.\"\n",
    "   → Son 3 ítems distintos.\n",
    "\n",
    "2) Para CADA ítem, clasificarlo como:\n",
    "\n",
    "   ● ACTIVIDADES PREVISTAS O RECORDATORIOS  → tipo = \"Evento\"\n",
    "     Ejemplos:\n",
    "     - \"Ir al neurólogo el martes 25 de noviembre a las 15:00.\"\n",
    "     - \"Cumpleaños de Pepita jueves 27 de noviembre.\"\n",
    "     - \"Tomar té con Juanita este lunes a las 16:00 en su casa.\"\n",
    "\n",
    "     Para cada Evento extrae:\n",
    "     - fecha: texto amigable de la fecha (\"martes 25 de noviembre\", \"este lunes\", etc.).\n",
    "     - hora: en formato HH:MM si es posible (\"15:00\", \"16:00\"), o null si no se menciona.\n",
    "     - descripcion: frase corta que describa el evento (\"Ir al neurólogo\", \"Cumpleaños de Pepita\").\n",
    "     - personas: lista de nombres de personas mencionadas, si las hay.\n",
    "     - lugar: lugar mencionado si aplica (\"su casa\", \"el hospital\", \"el parque\", etc.).\n",
    "     - clasificacion: null\n",
    "     - responsable_requerido: null\n",
    "\n",
    "   ● RECUERDOS O PEDIDOS → tipo = \"Recuerdo\"\n",
    "     Ejemplos:\n",
    "     - \"¿Cómo estará Antonio Perez? No lo veo hace años, debería llamarlo.\"\n",
    "     - \"Sería bueno comprar una nueva almohada.\"\n",
    "     - \"Qué linda fue la graduación de mi nieta, qué buenos recuerdos.\"\n",
    "\n",
    "     Para cada Recuerdo extrae:\n",
    "     - clasificacion (una sola palabra, minúsculas):\n",
    "         * \"tarea\"       → acción concreta que la persona podría hacer: llamar, visitar, anotar algo.\n",
    "         * \"compra\"      → comprar algo (ej: \"comprar almohada\", \"comprar limones\").\n",
    "         * \"pensamiento\" → reflexión/recuerdo/comentario sin acción clara.\n",
    "         * \"otro\"        → si no encaja en lo anterior.\n",
    "     - responsable_requerido:\n",
    "         * \"Si\"  → si parece algo que otra persona (familiar/cuidador) debería gestionar\n",
    "                   (especialmente compras u otras gestiones).\n",
    "         * \"No\"  → si es algo que la persona mayor podría hacer sola o es solo un recuerdo/pensamiento.\n",
    "     - descripcion: frase corta y accionable si corresponde:\n",
    "         * \"Llamar a Antonio Perez\"\n",
    "         * \"Comprar limones\"\n",
    "         * \"Recuerdo graduación de mi nieta\"\n",
    "     - personas: lista de nombres de personas mencionadas, si las hay.\n",
    "     - lugar: lugar mencionado si aplica.\n",
    "     - fecha: normalmente null, a menos que se mencione explícitamente una fecha.\n",
    "     - hora: normalmente null, a menos que se mencione explícitamente una hora.\n",
    "\n",
    "   ● OTROS CASOS → tipo = \"Ninguno\"\n",
    "     Si el fragmento no parece ni Evento ni Recuerdo útil (ruido, cosas sin sentido, etc.).\n",
    "     En ese caso:\n",
    "     - tipo = \"Ninguno\"\n",
    "     - puedes dejar el resto en null/listas vacías.\n",
    "\n",
    "MUY IMPORTANTE – FORMATO DE RESPUESTA:\n",
    "--------------------------------------\n",
    "Debes responder SIEMPRE con una LISTA JSON (array JSON) que contenga UN OBJETO POR ÍTEM.\n",
    "\n",
    "Ejemplos de salida válidos:\n",
    "\n",
    "1) Cuando hay varios ítems:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"tipo\": \"Evento\",\n",
    "    \"fecha\": \"jueves 27 de noviembre\",\n",
    "    \"hora\": null,\n",
    "    \"descripcion\": \"Cumpleaños de mi hija\",\n",
    "    \"clasificacion\": null,\n",
    "    \"responsable_requerido\": null,\n",
    "    \"personas\": [\"mi hija\"],\n",
    "    \"lugar\": null\n",
    "  },\n",
    "  {\n",
    "    \"tipo\": \"Recuerdo\",\n",
    "    \"fecha\": null,\n",
    "    \"hora\": null,\n",
    "    \"descripcion\": \"Comprar limones\",\n",
    "    \"clasificacion\": \"compra\",\n",
    "    \"responsable_requerido\": \"Si\",\n",
    "    \"personas\": [],\n",
    "    \"lugar\": null\n",
    "  }\n",
    "]\n",
    "\n",
    "2) Cuando solo hay un ítem:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"tipo\": \"Recuerdo\",\n",
    "    \"fecha\": null,\n",
    "    \"hora\": null,\n",
    "    \"descripcion\": \"Llamar a Juanito Perez\",\n",
    "    \"clasificacion\": \"tarea\",\n",
    "    \"responsable_requerido\": \"No\",\n",
    "    \"personas\": [\"Juanito Perez\"],\n",
    "    \"lugar\": null\n",
    "  }\n",
    "]\n",
    "\n",
    "3) Cuando no hay nada útil:\n",
    "\n",
    "[]\n",
    "\n",
    "Reglas:\n",
    "- SIEMPRE responde con una lista JSON: empieza con [ y termina con ].\n",
    "- NO añadas comentarios, explicaciones ni texto fuera del JSON.\n",
    "- Si no hay personas, usa \"personas\": [].\n",
    "- Si no hay fecha/hora/lugar, usa null en esos campos.\n",
    "\"\"\"\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": texto},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw = completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"No se pudo parsear JSON. Respuesta cruda del modelo:\")\n",
    "        print(raw)\n",
    "        raise\n",
    "\n",
    "    # Por seguridad: si el modelo devolviera un solo objeto en vez de lista\n",
    "    if isinstance(data, dict):\n",
    "        data = [data]\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f504da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necesito que me anotes que el lunes 24 es el cumpleaños de mi hija Antonia. Además necesito conseguirme el número de Juanito Pérez porque me he acordado mucho de él y no sé cómo comunicarme con él. Lo último es que se me acabaron los limones.\n"
     ]
    }
   ],
   "source": [
    "# Ruta a tu archivo de audio\n",
    "AUDIO_PATH = \"audios/multi_1.m4a\"  # cámbialo por tu archivo\n",
    "\n",
    "texto=transcribe(AUDIO_PATH)\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1139ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ítem 1:\n",
      "{'tipo': 'Evento', 'fecha': 'lunes 24', 'hora': None, 'descripcion': 'Cumpleaños de mi hija Antonia', 'clasificacion': None, 'responsable_requerido': None, 'personas': ['Antonia'], 'lugar': None}\n",
      "\n",
      "Ítem 2:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Conseguir el número de Juanito Pérez', 'clasificacion': 'tarea', 'responsable_requerido': 'Si', 'personas': ['Juanito Pérez'], 'lugar': None}\n",
      "\n",
      "Ítem 3:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Comprar limones', 'clasificacion': 'compra', 'responsable_requerido': 'Si', 'personas': [], 'lugar': None}\n"
     ]
    }
   ],
   "source": [
    "items = procesar_memoria_con_chatgpt(texto)\n",
    "for i, item in enumerate(items, start=1):\n",
    "    print(f\"\\nÍtem {i}:\")\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a2257",
   "metadata": {},
   "source": [
    "## Carga de archivos (examenes y recetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4057fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "DOCUMENT_SYSTEM_PROMPT = \"\"\"\n",
    "Eres un asistente que analiza DOCUMENTOS MÉDICOS para una persona mayor.\n",
    "\n",
    "Recibirás el contenido de un documento, que puede ser:\n",
    "- una RECETA MÉDICA\n",
    "- un EXAMEN MÉDICO (por ejemplo exámenes de sangre, radiografías, resonancias, etc.)\n",
    "- u otro tipo de documento sin relevancia para estos casos.\n",
    "\n",
    "Tu tarea es:\n",
    "1) Detectar si el documento es principalmente una RECETA, un EXAMEN o NINGUNO.\n",
    "2) Según el tipo, devolver SIEMPRE UN SOLO JSON con uno de estos formatos:\n",
    "\n",
    "CASO A) RECETA MÉDICA\n",
    "----------------------\n",
    "Devuelve:\n",
    "\n",
    "{\n",
    "  \"tipo\": \"receta\",\n",
    "  \"fecha_receta\": \"AAAA-MM-DD\" o \"19 nov 2025\",\n",
    "  \"medicamentos\": [\n",
    "    {\n",
    "      \"nombre\": \"nombre del medicamento\",\n",
    "      \"dosis\": \"texto de dosis\",\n",
    "      \"instruccion_original\": \"texto original de la indicación\",\n",
    "      \"tomas\": [\n",
    "        \"fecha hora\",\n",
    "        \"fecha hora\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Reglas:\n",
    "- \"fecha_receta\": la fecha que aparezca en la receta (si no aparece, usa null).\n",
    "- Asume SIEMPRE que el tratamiento empieza el DÍA SIGUIENTE a \"fecha_receta\".\n",
    "- Si dice algo como \"3 veces/día por 3 días\":\n",
    "  - debes calcular todas las tomas y listarlas en \"tomas\".\n",
    "  - reparte las tomas en horarios razonables (ejemplo: 08:00, 16:00, 24:00)\n",
    "    para cumplir con las X tomas al día.\n",
    "- Si hay varios medicamentos, agrega un objeto en \"medicamentos\" por cada uno.\n",
    "\n",
    "CASO B) EXAMEN MÉDICO\n",
    "----------------------\n",
    "Devuelve:\n",
    "\n",
    "{\n",
    "  \"tipo\": \"examen\",\n",
    "  \"fecha\": \"AAAA-MM-DD\" o \"19 nov 2025\",\n",
    "  \"tipo_examen\": \"nombre corto del examen (ej: 'perfil lipídico', 'hemograma')\",\n",
    "  \"resultado\": \"normal\" o una frase breve como 'glucosa por encima de los rangos normales'\",\n",
    "  \"es_normal\": true o false o null\n",
    "}\n",
    "\n",
    "Reglas:\n",
    "- Usa la fecha que aparezca como fecha del examen o informe.\n",
    "- Para \"resultado\" y \"es_normal\":\n",
    "  - Si todos los valores importantes están dentro de rango\n",
    "    y/o el informe dice que es normal → resultado: \"normal\", es_normal: true.\n",
    "  - Si algunos valores están fuera de rango o el informe indica algún hallazgo,\n",
    "    describe brevemente el hallazgo → es_normal: false.\n",
    "  - NO inventes resultados ni rangos.\n",
    "    SOLO marca anormal si:\n",
    "      * los rangos de referencia del propio reporte lo indican, o\n",
    "      * el comentario del médico menciona algo alterado.\n",
    "  - Si no hay suficiente información → resultado: \"no se puede determinar con certeza\",\n",
    "    es_normal: null.\n",
    "\n",
    "CASO C) OTRO\n",
    "------------\n",
    "Si el documento no parece ni receta ni examen, devuelve:\n",
    "\n",
    "{\n",
    "  \"tipo\": \"ninguno\"\n",
    "}\n",
    "\n",
    "FORMATO:\n",
    "--------\n",
    "- NO añadas explicaciones ni texto fuera del JSON.\n",
    "- Devuelve solo UN objeto JSON.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extraer_texto_pdf(ruta_pdf: str) -> str:\n",
    "    reader = PdfReader(ruta_pdf)\n",
    "    texto = []\n",
    "    for page in reader.pages:\n",
    "        t = page.extract_text()\n",
    "        if t:\n",
    "            texto.append(t)\n",
    "    return \"\\n\\n\".join(texto)\n",
    "\n",
    "def analizar_pdf_documento(ruta_pdf: str) -> dict:\n",
    "    texto = extraer_texto_pdf(ruta_pdf)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": DOCUMENT_SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Este es el contenido de un documento médico:\\n\\n{texto}\\n\\nDevuelve el JSON correspondiente.\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw = completion.choices[0].message.content\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"No se pudo parsear JSON. Respuesta cruda:\")\n",
    "        print(raw)\n",
    "        raise\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174a00a",
   "metadata": {},
   "source": [
    "### Resultado examen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6104833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tipo': 'examen', 'fecha': '2024-07-05', 'tipo_examen': 'perfil bioquímico', 'resultado': 'algunos valores fuera de rango, recuento de hematíes y linfocitos bajos, monocitos altos', 'es_normal': False}\n"
     ]
    }
   ],
   "source": [
    "resultado = analizar_pdf_documento(\"pdfs/lab.pdf\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b545a23",
   "metadata": {},
   "source": [
    "### Resultado receta médica\n",
    "- Agregar fotos de recetas a mano\n",
    "- Agregar fotos de recetas impresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70691d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 30 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tipo': 'receta', 'fecha_receta': '2025-04-15', 'medicamentos': [{'nombre': 'escitalopram 10 mg comprimido', 'dosis': '0.5 comprimido', 'instruccion_original': 'Administrar cada 24 horas', 'tomas': ['2025-04-16 08:00']}]}\n"
     ]
    }
   ],
   "source": [
    "resultado = analizar_pdf_documento(\"pdfs/receta.pdf\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a55ed",
   "metadata": {},
   "source": [
    "## Resupuesta del agente a la persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb301a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texto_a_audio(\n",
    "    texto: str,\n",
    "    ruta_salida: str = \"respuesta.mp3\",\n",
    "    voz: str = \"alloy\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convierte un texto en audio usando gpt-4o-mini-tts y lo guarda como MP3.\n",
    "    Devuelve la ruta del archivo generado.\n",
    "    \"\"\"\n",
    "\n",
    "    speech_file_path = Path(ruta_salida)\n",
    "\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",  # modelo TTS\n",
    "        voice=voz,                # alloy, nova, shimmer, etc.\n",
    "        input=texto\n",
    "        # opcional: instructions=\"Habla lento y con tono cálido.\"\n",
    "    )\n",
    "\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n",
    "    return str(speech_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b672339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio generado en: respuestas/recordatorio_semana.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "#Respuesta hardcodeada por ahora\n",
    "respuesta = \"Tienes una hora con el neurólogo el martes a las 15:00.\"\n",
    "\n",
    "ruta_audio = texto_a_audio(\n",
    "        texto=respuesta,\n",
    "        ruta_salida=\"respuestas/recordatorio_semana.mp3\",\n",
    "        voz=\"alloy\"  # prueba también \"nova\", \"shimmer\", etc.\n",
    "    )\n",
    "\n",
    "print(\"Audio generado en:\", ruta_audio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977882d7",
   "metadata": {},
   "source": [
    "## Pruebas completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9121032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cargar_memoria():\n",
    "    \"\"\"Carga la memoria desde disco (lista de registros).\"\"\"\n",
    "    if not os.path.exists(MEMORY_FILE):\n",
    "        return []\n",
    "    with open(MEMORY_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def guardar_memoria(memoria):\n",
    "    \"\"\"Guarda la lista completa de memoria en disco.\"\"\"\n",
    "    with open(MEMORY_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(memoria, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def agregar_items_a_memoria(items, texto_original: str):\n",
    "    \"\"\"\n",
    "    items: lista devuelta por procesar_memoria_con_chatgpt(texto)\n",
    "    texto_original: transcripción completa del audio\n",
    "    \"\"\"\n",
    "    memoria = cargar_memoria()\n",
    "    next_id = (memoria[-1][\"id\"] + 1) if memoria else 1\n",
    "\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    for item in items:\n",
    "        registro = {\n",
    "            \"id\": next_id,\n",
    "            \"timestamp_guardado\": timestamp,\n",
    "            \"texto_original\": texto_original,\n",
    "            \"item\": item  # acá va el dict con tipo, fecha, hora, etc.\n",
    "        }\n",
    "        memoria.append(registro)\n",
    "        next_id += 1\n",
    "\n",
    "    guardar_memoria(memoria)\n",
    "    return memoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cc0f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_interaccion(texto: str) -> dict:\n",
    "    \"\"\"\n",
    "    Clasifica el texto en:\n",
    "      - captura: está contando cosas nuevas para guardar (eventos/recuerdos)\n",
    "      - consulta: está preguntando sobre lo que ya hay en memoria\n",
    "      - otro: ninguna de las anteriores\n",
    "\n",
    "    Devuelve un dict, por ejemplo:\n",
    "      {\"tipo_interaccion\": \"captura\"}\n",
    "      {\"tipo_interaccion\": \"consulta\", \"pregunta\": \"recuérdame todo lo que tengo para esta semana\"}\n",
    "    \"\"\"\n",
    "    base_instructions = \"\"\"\n",
    "Eres un RUTER de intenciones para un asistente de memoria de personas mayores.\n",
    "\n",
    "Dado el texto que dijo la persona, debes decidir si es:\n",
    "\n",
    "1) \"captura\"\n",
    "   - Cuando parece que la persona está contando cosas nuevas para que se guarden\n",
    "     como eventos o recuerdos.\n",
    "   - Ejemplos:\n",
    "     - \"El jueves es el cumpleaños de mi hija.\"\n",
    "     - \"Tengo que comprar limones.\"\n",
    "     - \"Hace mucho que no sé de Juanito Perez, debería llamarlo.\"\n",
    "\n",
    "2) \"consulta\"\n",
    "   - Cuando la persona está pidiendo que le recuerdes algo que ya debería estar\n",
    "     en memoria.\n",
    "   - Ejemplos:\n",
    "     - \"Recuérdame todo lo que tengo para esta semana.\"\n",
    "     - \"¿Qué recordatorios tengo hoy?\"\n",
    "     - \"¿Qué cosas tenía pendientes con Juanito Perez?\"\n",
    "\n",
    "3) \"otro\"\n",
    "   - Cuando no encaja en los casos anteriores.\n",
    "\n",
    "FORMATO DE RESPUESTA:\n",
    "---------------------\n",
    "Devuelve SIEMPRE un JSON con una de estas formas:\n",
    "\n",
    "{\"tipo_interaccion\": \"captura\"}\n",
    "\n",
    "{\"tipo_interaccion\": \"consulta\", \"pregunta\": \"texto de la pregunta (puede ser el mismo texto original)\"}\n",
    "\n",
    "{\"tipo_interaccion\": \"otro\"}\n",
    "\"\"\"\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": texto},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw = completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"No se pudo parsear JSON del router. Respuesta cruda:\")\n",
    "        print(raw)\n",
    "        raise\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95d76162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder_consulta_desde_memoria(pregunta: str, max_items: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    Usa TODO lo que hay en memoria.json (eventos, recuerdos, recetas, etc.)\n",
    "    para responder a una pregunta del tipo:\n",
    "      - \"¿Qué tengo que hacer hoy?\"\n",
    "      - \"¿Qué fue lo que hice ayer?\"\n",
    "      - \"¿Qué remedios tengo que tomarme?\"\n",
    "      - \"¿Qué cosas tenía pendientes con Juanito?\"\n",
    "    Devuelve TEXTO listo para leer en voz alta.\n",
    "    \"\"\"\n",
    "\n",
    "    memoria = cargar_memoria()\n",
    "    # Tomamos los últimos N registros para no pasar un JSON infinito\n",
    "    recientes = memoria[-max_items:]\n",
    "    contexto_memorias = json.dumps(recientes, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Fecha de \"hoy\" para que el modelo pueda interpretar \"hoy\", \"mañana\", \"ayer\"\n",
    "    fecha_hoy = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    base_instructions = f\"\"\"\n",
    "Eres un asistente de MEMORIA para una persona mayor.\n",
    "\n",
    "Tienes acceso a:\n",
    "- Una PREGUNTA en lenguaje natural.\n",
    "- Una lista de MEMORIAS en formato JSON.\n",
    "  Cada memoria tiene:\n",
    "    - id\n",
    "    - timestamp_guardado\n",
    "    - origen (p.ej. \"audio\", \"documento_medico\")\n",
    "    - texto_original (si viene de audio)\n",
    "    - item: con campos como:\n",
    "        * tipo: \"Evento\", \"Recuerdo\", \"receta\", \"examen\", \"Ninguno\", etc.\n",
    "        * fecha, hora, descripcion, clasificacion, responsable_requerido, personas, lugar...\n",
    "        * en el caso de recetas:\n",
    "            - medicamentos: lista de medicamentos con campos como \"nombre\", \"dosis\", \"tomas\" (fechas/horas)\n",
    "\n",
    "La fecha de HOY es: {fecha_hoy}\n",
    "\n",
    "Tu tarea:\n",
    "- Interpretar la pregunta y buscar en las MEMORIAS la información relevante.\n",
    "- Algunos ejemplos:\n",
    "    * Si pregunta \"¿Qué tengo que hacer hoy?\" → revisar items de tipo \"Evento\"\n",
    "      cuya fecha (o tomas de medicamentos) coincidan con HOY.\n",
    "    * Si pregunta \"¿Qué fue lo que hice ayer?\" → buscar eventos o recuerdos con fecha de AYER.\n",
    "    * Si pregunta \"¿Qué remedios tengo que tomarme?\" → revisar items de tipo \"receta\"\n",
    "      y sus tomas (especialmente las de hoy) y explicar de forma simple.\n",
    "    * Si pregunta por una persona (\"¿Qué cosas tenía pendientes con Juanito Perez?\")\n",
    "      → buscar en descripciones / personas de items tipo \"Recuerdo\" o \"Evento\" donde aparezca ese nombre.\n",
    "\n",
    "- Usa el campo \"tipo\" y la información de fechas/horas/descripcion para priorizar:\n",
    "    * tipo \"Evento\" → cosas que la persona debe hacer en una fecha/hora.\n",
    "    * tipo \"Recuerdo\" con clasificacion \"tarea\" o \"compra\" → pendientes.\n",
    "    * tipo \"receta\" → medicación, tomas de remedios.\n",
    "\n",
    "- Si NO encuentras nada útil o no hay información suficiente, dilo claramente\n",
    "  (por ejemplo: \"Por ahora no tengo nada guardado para hoy\" o\n",
    "   \"No tengo información sobre remedios activos en este momento\").\n",
    "\n",
    "FORMA DE RESPONDER:\n",
    "- Responde SIEMPRE en español.\n",
    "- Usa un tono claro, cálido y breve, pensado para ser escuchado en voz alta.\n",
    "- Máximo 2 o 3 frases.\n",
    "- NO devuelvas JSON, solo el texto de la respuesta.\n",
    "\"\"\"\n",
    "\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "PREGUNTA:\n",
    "{pregunta}\n",
    "\n",
    "MEMORIAS (JSON):\n",
    "{contexto_memorias}\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    respuesta_texto = completion.choices[0].message.content.strip()\n",
    "    return respuesta_texto\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reemplazamos esta funcion por otra, pero la dejo por si tenemos que volver a ella\n",
    "def responder_consulta_desde_memoria_old(pregunta: str, max_items: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    Usa la memoria guardada para responder a la pregunta.\n",
    "    Devuelve solo el TEXTO de la respuesta (para luego pasarlo a voz).\n",
    "    \"\"\"\n",
    "    memoria = cargar_memoria()\n",
    "    # Tomamos los últimos N registros para no mandar todo\n",
    "    recientes = memoria[-max_items:]\n",
    "\n",
    "    # Los pasamos como JSON de contexto\n",
    "    contexto_memorias = json.dumps(recientes, ensure_ascii=False, indent=2)\n",
    "\n",
    "    base_instructions = \"\"\"\n",
    "Eres un asistente de MEMORIA para una persona mayor.\n",
    "\n",
    "Recibes:\n",
    "- Una PREGUNTA en lenguaje natural.\n",
    "- Una lista de MEMORIAS en formato JSON.\n",
    "  Cada memoria tiene:\n",
    "    - id\n",
    "    - timestamp_guardado\n",
    "    - texto_original (lo que la persona dijo)\n",
    "    - item: con campos como tipo, fecha, hora, descripcion, clasificacion, etc.\n",
    "\n",
    "Tu tarea:\n",
    "- Responder a la pregunta usando SOLO la información de las MEMORIAS.\n",
    "- Si la persona pregunta cosas como:\n",
    "    \"Recuérdame todo lo que tengo para esta semana\"\n",
    "    \"¿Qué recordatorios tengo hoy?\"\n",
    "  revisa principalmente los items de tipo \"Evento\" y \"Recuerdo\" relevantes.\n",
    "- Si NO encuentras nada útil para la pregunta, dilo claramente.\n",
    "\n",
    "Responde SIEMPRE en español, en 1 o 2 frases, de forma clara y natural,\n",
    "pensando que la respuesta se escuchará en voz alta.\n",
    "NO devuelvas JSON, solo el texto de la respuesta.\n",
    "\"\"\"\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "PREGUNTA:\n",
    "{pregunta}\n",
    "\n",
    "MEMORIAS (JSON):\n",
    "{contexto_memorias}\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    respuesta_texto = completion.choices[0].message.content.strip()\n",
    "    return respuesta_texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8bad094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_audio_como_agente(\n",
    "    audio_path: str,\n",
    "    generar_audio_respuesta: bool = True,\n",
    "    ruta_audio_respuesta: str = \"respuestas/respuesta_agente.mp3\",\n",
    "    voz: str = \"alloy\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Transcribe el audio.\n",
    "    2) Decide si es captura o consulta.\n",
    "    3) Si es captura:\n",
    "         - extrae items con procesar_memoria_con_chatgpt\n",
    "         - los guarda en memoria.json\n",
    "    4) Si es consulta:\n",
    "         - responde usando la memoria\n",
    "         - opcionalmente genera audio con texto_a_audio\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n=== Procesando audio: {audio_path} ===\")\n",
    "    texto = transcribe(audio_path)\n",
    "    print(\"\\nTRANSCRIPCIÓN:\")\n",
    "    print(texto)\n",
    "\n",
    "    # Clasificar interacción\n",
    "    clasif = clasificar_interaccion(texto)\n",
    "    print(\"\\nCLASIFICACIÓN:\", clasif)\n",
    "\n",
    "    tipo = clasif.get(\"tipo_interaccion\")\n",
    "\n",
    "    if tipo == \"captura\":\n",
    "        print(\"\\n→ Modo CAPTURA: extrayendo eventos/recuerdos...\")\n",
    "        items = procesar_memoria_con_chatgpt(texto)\n",
    "        print(f\"Se detectaron {len(items)} ítems:\")\n",
    "        for i, item in enumerate(items, start=1):\n",
    "            print(f\"\\nÍtem {i}:\")\n",
    "            print(item)\n",
    "\n",
    "        memoria_actualizada = agregar_items_a_memoria(items, texto)\n",
    "        print(f\"\\nMemoria total ahora tiene {len(memoria_actualizada)} registros.\")\n",
    "        respuesta_texto = \"He guardado tus recuerdos y recordatorios.\"\n",
    "\n",
    "    elif tipo == \"consulta\":\n",
    "        print(\"\\n→ Modo CONSULTA: respondiendo usando la memoria...\")\n",
    "        pregunta = clasif.get(\"pregunta\", texto)\n",
    "        respuesta_texto = responder_consulta_desde_memoria(pregunta)\n",
    "        print(\"\\nRESPUESTA DEL AGENTE:\")\n",
    "        print(respuesta_texto)\n",
    "\n",
    "    else:\n",
    "        print(\"\\n→ Modo OTRO: no se clasifica como captura ni consulta.\")\n",
    "        respuesta_texto = \"No estoy seguro de qué hacer con eso, pero puedo intentarlo si lo repites como un recordatorio o una pregunta.\"\n",
    "\n",
    "    # Generar audio de la respuesta, si se pide\n",
    "    ruta_audio = None\n",
    "    if generar_audio_respuesta:\n",
    "        # Asegurarnos de que exista la carpeta\n",
    "        ruta = Path(ruta_audio_respuesta)\n",
    "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ruta_audio = texto_a_audio(\n",
    "            texto=respuesta_texto,\n",
    "            ruta_salida=str(ruta),\n",
    "            voz=voz,\n",
    "        )\n",
    "        print(\"\\nAudio de respuesta generado en:\", ruta_audio)\n",
    "\n",
    "    return {\n",
    "        \"texto_respuesta\": respuesta_texto,\n",
    "        \"ruta_audio_respuesta\": ruta_audio\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4584fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_memoria():\n",
    "    if not os.path.exists(MEMORY_FILE):\n",
    "        return []\n",
    "    with open(MEMORY_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def guardar_memoria(memoria):\n",
    "    with open(MEMORY_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(memoria, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def guardar_documento_medico_en_memoria(doc_info: dict, ruta_archivo: str):\n",
    "    \"\"\"\n",
    "    Guarda en memoria un documento médico (receta o examen).\n",
    "\n",
    "    doc_info: dict devuelto por analizar_imagen_documento / analizar_pdf_documento\n",
    "              ej:\n",
    "              {\n",
    "                \"tipo\": \"receta\",\n",
    "                \"fecha_receta\": \"2025-11-19\",\n",
    "                \"medicamentos\": [...]\n",
    "              }\n",
    "\n",
    "              o\n",
    "\n",
    "              {\n",
    "                \"tipo\": \"examen\",\n",
    "                \"fecha\": \"2025-11-19\",\n",
    "                \"tipo_examen\": \"perfil lipídico\",\n",
    "                \"resultado\": \"normal\",\n",
    "                \"es_normal\": true\n",
    "              }\n",
    "\n",
    "    ruta_archivo: ruta local del archivo usado como origen (jpg, pdf, etc.)\n",
    "    \"\"\"\n",
    "    memoria = cargar_memoria()\n",
    "    next_id = (memoria[-1][\"id\"] + 1) if memoria else 1\n",
    "\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    registro = {\n",
    "        \"id\": next_id,\n",
    "        \"timestamp_guardado\": timestamp,\n",
    "        \"origen\": \"documento_medico\",\n",
    "        \"ruta_archivo\": ruta_archivo,\n",
    "        \"item\": doc_info\n",
    "    }\n",
    "\n",
    "    memoria.append(registro)\n",
    "    guardar_memoria(memoria)\n",
    "\n",
    "    return registro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0862e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoy no tienes eventos programados, pero hay algunas cosas que deberías recordar. Necesitas conseguir el número de Juanito Pérez y también comprar limones. ¡No te olvides de eso!\n",
      "No tengo información sobre remedios activos en este momento. Si necesitas ayuda con otra cosa, no dudes en decírmelo.\n",
      "Ayer no tengo información específica sobre lo que hiciste. Sin embargo, tienes pendiente conseguir el número de Juanito Pérez y comprar limones. También recuerda que el lunes 24 es el cumpleaños de tu hija Antonia.\n"
     ]
    }
   ],
   "source": [
    "print(responder_consulta_desde_memoria(\"Recuérdame qué tengo que hacer hoy.\"))\n",
    "\n",
    "# Pregunta tipo \"qué remedios\"\n",
    "print(responder_consulta_desde_memoria(\"¿Qué remedios tengo que tomarme hoy?\"))\n",
    "\n",
    "# Pregunta tipo \"qué hice ayer\"\n",
    "print(responder_consulta_desde_memoria(\"¿Qué fue lo que hice ayer?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "750eaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_receta_imagen_y_guardar(ruta_imagen: str):\n",
    "    \"\"\"\n",
    "    Analiza una imagen (foto de receta / examen) y, si es receta/examen,\n",
    "    la guarda en memoria.json.\n",
    "    \"\"\"\n",
    "    doc_info = analizar_imagen_documento(ruta_imagen)\n",
    "\n",
    "    if doc_info.get(\"tipo\") in [\"receta\", \"examen\"]:\n",
    "        registro = guardar_documento_medico_en_memoria(doc_info, ruta_imagen)\n",
    "        print(\"Documento médico guardado en memoria:\")\n",
    "        print(json.dumps(registro, ensure_ascii=False, indent=2))\n",
    "        return registro\n",
    "    else:\n",
    "        print(\"El documento no parece receta ni examen (tipo:\", doc_info.get(\"tipo\"), \")\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3a5faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_examen_pdf_y_guardar(ruta_pdf: str):\n",
    "    \"\"\"\n",
    "    Analiza un PDF (examen) y, si es receta/examen,\n",
    "    lo guarda en memoria.json.\n",
    "    \"\"\"\n",
    "    doc_info = analizar_pdf_documento(ruta_pdf)\n",
    "\n",
    "    if doc_info.get(\"tipo\") in [\"receta\", \"examen\"]:\n",
    "        registro = guardar_documento_medico_en_memoria(doc_info, ruta_pdf)\n",
    "        print(\"Documento médico guardado en memoria:\")\n",
    "        print(json.dumps(registro, ensure_ascii=False, indent=2))\n",
    "        return registro\n",
    "    else:\n",
    "        print(\"El documento no parece receta ni examen (tipo:\", doc_info.get(\"tipo\"), \")\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34bba672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Procesando audio: audios/multi_1.m4a ===\n",
      "\n",
      "TRANSCRIPCIÓN:\n",
      "Necesito que me anotes que el lunes 24 es el cumpleaños de mi hija Antonia. Además necesito conseguirme el número de Juanito Pérez porque me he acordado mucho de él y no sé cómo comunicarme con él. Lo último es que se me acabaron los limones.\n",
      "\n",
      "CLASIFICACIÓN: {'tipo_interaccion': 'captura'}\n",
      "\n",
      "→ Modo CAPTURA: extrayendo eventos/recuerdos...\n",
      "Se detectaron 3 ítems:\n",
      "\n",
      "Ítem 1:\n",
      "{'tipo': 'Evento', 'fecha': 'lunes 24', 'hora': None, 'descripcion': 'Cumpleaños de mi hija Antonia', 'clasificacion': None, 'responsable_requerido': None, 'personas': ['Antonia'], 'lugar': None}\n",
      "\n",
      "Ítem 2:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Conseguir el número de Juanito Pérez', 'clasificacion': 'tarea', 'responsable_requerido': 'Si', 'personas': ['Juanito Pérez'], 'lugar': None}\n",
      "\n",
      "Ítem 3:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Comprar limones', 'clasificacion': 'compra', 'responsable_requerido': 'Si', 'personas': [], 'lugar': None}\n",
      "\n",
      "Memoria total ahora tiene 7 registros.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio de respuesta generado en: respuestas/respuesta_agente.mp3\n",
      "\n",
      "=== Procesando audio: audios/pregunta_semana.m4a ===\n",
      "\n",
      "TRANSCRIPCIÓN:\n",
      "Recuérdame todo lo que tengo para esta semana y para la próxima.\n",
      "\n",
      "CLASIFICACIÓN: {'tipo_interaccion': 'consulta', 'pregunta': 'Recuérdame todo lo que tengo para esta semana y para la próxima.'}\n",
      "\n",
      "→ Modo CONSULTA: respondiendo usando la memoria...\n",
      "\n",
      "RESPUESTA DEL AGENTE:\n",
      "Para esta semana, el lunes 24 es el cumpleaños de tu hija Antonia. También tienes que conseguir el número de Juanito Pérez y comprar limones. No tengo información sobre eventos para la próxima semana.\n",
      "\n",
      "Audio de respuesta generado en: respuestas/respuesta_agente.mp3\n",
      "Documento médico guardado en memoria:\n",
      "{\n",
      "  \"id\": 8,\n",
      "  \"timestamp_guardado\": \"2025-11-22T14:26:01.772129\",\n",
      "  \"origen\": \"documento_medico\",\n",
      "  \"ruta_archivo\": \"pdfs/lab.pdf\",\n",
      "  \"item\": {\n",
      "    \"tipo\": \"examen\",\n",
      "    \"fecha\": \"2024-07-05\",\n",
      "    \"tipo_examen\": \"perfil bioquímico\",\n",
      "    \"resultado\": \"glucosa dentro de los rangos normales, pero recuento de hematíes ligeramente bajo y linfocitos bajos\",\n",
      "    \"es_normal\": false\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 8,\n",
       " 'timestamp_guardado': '2025-11-22T14:26:01.772129',\n",
       " 'origen': 'documento_medico',\n",
       " 'ruta_archivo': 'pdfs/lab.pdf',\n",
       " 'item': {'tipo': 'examen',\n",
       "  'fecha': '2024-07-05',\n",
       "  'tipo_examen': 'perfil bioquímico',\n",
       "  'resultado': 'glucosa dentro de los rangos normales, pero recuento de hematíes ligeramente bajo y linfocitos bajos',\n",
       "  'es_normal': False}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Audio con cosas para guardar\n",
    "procesar_audio_como_agente(\"audios/multi_1.m4a\")\n",
    "\n",
    "# 2) Audio con una consulta (la persona hace una pregunta (audio pregunta_semana.mp4) y el agente responde con un audio que se guarda en respuestas)\n",
    "procesar_audio_como_agente(\"audios/pregunta_semana.m4a\")\n",
    "\n",
    "# 3) Guardar en memoria archivo de examen/receta\n",
    "procesar_examen_pdf_y_guardar(\"pdfs/lab.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2eb364",
   "metadata": {},
   "source": [
    "## Interacción proactiva del agente con la persona (en función de sus recuerdos y otros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa8ed398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_pregunta_proactiva(max_items: int = 50) -> dict:\n",
    "    \"\"\"\n",
    "    Genera una pregunta o mensaje proactivo para la persona mayor,\n",
    "    usando el perfil y la memoria existente.\n",
    "\n",
    "    Devuelve un dict como:\n",
    "    {\n",
    "      \"tipo\": \"memoria_evento\" | \"memoria_general\" | \"ejercicio_cognitivo\" | \"compañia\",\n",
    "      \"texto\": \"Pregunta o frase para decirle a la persona\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    memoria = cargar_memoria()\n",
    "    recientes = memoria[-max_items:]\n",
    "    contexto_memorias = json.dumps(recientes, ensure_ascii=False, indent=2)\n",
    "\n",
    "    fecha_hoy = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    base_instructions = f\"\"\"\n",
    "Eres un asistente de MEMORIA y COMPAÑÍA para una persona mayor.\n",
    "\n",
    "Tu objetivo es hacerle una pregunta o comentario proactivo que:\n",
    "- le ayude a ejercitar la memoria,\n",
    "- o le dé compañía,\n",
    "- o le proponga un pequeño ejercicio mental sencillo.\n",
    "\n",
    "Tienes:\n",
    "- La fecha de HOY: {fecha_hoy}\n",
    "- Una lista de MEMORIAS en JSON (eventos, recuerdos, etc.), que pueden incluir:\n",
    "    * tipo \"Evento\": cumpleaños, citas, salidas.\n",
    "    * tipo \"Recuerdo\": pensamientos, recuerdos bonitos, tareas, compras.\n",
    "    * tipo \"receta\": información de medicación (opcional).\n",
    "    * tipo \"examen\": exámenes médicos (opcional).\n",
    "\n",
    "Ideas de cosas que puedes preguntarle:\n",
    "- Preguntar por algún evento reciente:\n",
    "    * \"¿Qué me puedes contar del cumpleaños de tu hija al que fuiste hace poco?\"\n",
    "- Preguntas generales de memoria autobiográfica:\n",
    "    * \"¿Me puedes decir el nombre de tus nietos?\"\n",
    "    * \"¿Cuál es tu recuerdo más feliz de la infancia?\"\n",
    "- Ejercicios mentales suaves y amistosos:\n",
    "    * \"¿Puedes nombrar cinco frutas diferentes?\"\n",
    "    * \"¿Puedes decirme qué día de la semana es hoy?\"\n",
    "- Conversación de compañía:\n",
    "    * \"Hoy estuve pensando en tus nietos. ¿Te gustaría contarme algo lindo de ellos?\"\n",
    "    * \"¿Qué fue lo más bonito que te pasó esta semana?\"\n",
    "\n",
    "Reglas:\n",
    "- Elige SOLO UNA pregunta o comentario para esta llamada.\n",
    "- Si en las memorias ves algo reciente (por ejemplo un cumpleaños, una salida, una cita médica),\n",
    "  puedes personalizar la pregunta refiriéndote a eso.\n",
    "- Si no ves nada especial, elige una pregunta general de recuerdos o un ejercicio mental sencillo.\n",
    "- Mantén la pregunta corta, clara y amable.\n",
    "\n",
    "FORMATO DE SALIDA (JSON):\n",
    "-------------------------\n",
    "Devuelve SIEMPRE un JSON con esta forma:\n",
    "\n",
    "{{\n",
    "  \"tipo\": \"memoria_evento\" | \"memoria_general\" | \"ejercicio_cognitivo\" | \"compañia\",\n",
    "  \"texto\": \"Pregunta o frase para decirle a la persona, en español.\"\n",
    "}}\n",
    "\n",
    "No añadas texto fuera del JSON.\n",
    "\"\"\"\n",
    "\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "MEMORIAS (JSON):\n",
    "{contexto_memorias}\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.6,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw = completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"No se pudo parsear JSON en generar_pregunta_proactiva. Respuesta cruda:\")\n",
    "        print(raw)\n",
    "        raise\n",
    "\n",
    "    if \"texto\" not in data:\n",
    "        data[\"texto\"] = \"¿Te gustaría contarme algo lindo de tu vida?\"\n",
    "    if \"tipo\" not in data:\n",
    "        data[\"tipo\"] = \"compañia\"\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e1acaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactuar_proactivamente(\n",
    "    generar_audio: bool = True,\n",
    "    ruta_audio_respuesta: str = \"respuestas/proactivo_pregunta.mp3\",\n",
    "    voz: str = \"alloy\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Genera una pregunta o comentario proactivo para la persona mayor,\n",
    "    opcionalmente lo convierte en audio y devuelve ambos.\n",
    "\n",
    "    Devuelve:\n",
    "    {\n",
    "      \"tipo\": ...,\n",
    "      \"pregunta_texto\": ...,\n",
    "      \"ruta_audio\": ... (o None si generar_audio=False)\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    proactivo = generar_pregunta_proactiva()\n",
    "    pregunta_texto = proactivo.get(\"texto\", \"¿Te gustaría contarme algo lindo de tu vida?\")\n",
    "    tipo = proactivo.get(\"tipo\", \"compañia\")\n",
    "\n",
    "    print(\"\\n=== INTERACCIÓN PROACTIVA ===\")\n",
    "    print(\"Tipo:\", tipo)\n",
    "    print(\"Pregunta:\", pregunta_texto)\n",
    "\n",
    "    ruta_audio = None\n",
    "    if generar_audio:\n",
    "        ruta = Path(ruta_audio_respuesta)\n",
    "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ruta_audio = texto_a_audio(\n",
    "            texto=pregunta_texto,\n",
    "            ruta_salida=str(ruta),\n",
    "            voz=voz,\n",
    "        )\n",
    "        print(\"Audio generado en:\", ruta_audio)\n",
    "\n",
    "    return {\n",
    "        \"tipo\": tipo,\n",
    "        \"pregunta_texto\": pregunta_texto,\n",
    "        \"ruta_audio\": ruta_audio,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44173adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INTERACCIÓN PROACTIVA ===\n",
      "Tipo: memoria_evento\n",
      "Pregunta: ¿Qué planes tienes para el cumpleaños de tu hija Antonia el lunes 24?\n",
      "Audio generado en: respuestas/proactivo_pregunta.mp3\n",
      "¿Qué planes tienes para el cumpleaños de tu hija Antonia el lunes 24?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "# Aplicación función de interaccion proactiva\n",
    "\n",
    "res = interactuar_proactivamente()\n",
    "print(res[\"pregunta_texto\"])\n",
    "# → lo mandas a reproducir con el mp3 en res[\"ruta_audio\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff5113d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Procesando audio: audios/respuesta_proactiva_1.m4a ===\n",
      "\n",
      "TRANSCRIPCIÓN:\n",
      "Quiero ir y estar con mis nietos. Quiero comer la torta caluga de mi nieta, Francisca, y volver temprano. Estoy un poco cansada.\n",
      "\n",
      "CLASIFICACIÓN: {'tipo_interaccion': 'captura'}\n",
      "\n",
      "→ Modo CAPTURA: extrayendo eventos/recuerdos...\n",
      "Se detectaron 4 ítems:\n",
      "\n",
      "Ítem 1:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Estar con mis nietos', 'clasificacion': 'pensamiento', 'responsable_requerido': 'No', 'personas': ['mis nietos'], 'lugar': None}\n",
      "\n",
      "Ítem 2:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Comer la torta caluga de mi nieta', 'clasificacion': 'pensamiento', 'responsable_requerido': 'No', 'personas': ['Francisca'], 'lugar': None}\n",
      "\n",
      "Ítem 3:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Volver temprano', 'clasificacion': 'pensamiento', 'responsable_requerido': 'No', 'personas': [], 'lugar': None}\n",
      "\n",
      "Ítem 4:\n",
      "{'tipo': 'Recuerdo', 'fecha': None, 'hora': None, 'descripcion': 'Estoy un poco cansada', 'clasificacion': 'pensamiento', 'responsable_requerido': 'No', 'personas': [], 'lugar': None}\n",
      "\n",
      "Memoria total ahora tiene 12 registros.\n",
      "\n",
      "Audio de respuesta generado en: respuestas/respuesta_agente.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'texto_respuesta': 'He guardado tus recuerdos y recordatorios.',\n",
       " 'ruta_audio_respuesta': 'respuestas/respuesta_agente.mp3'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procesar_audio_como_agente(\"audios/respuesta_proactiva_1.m4a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2824a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adicionales para que sea una conversación proactiva, no solo una única pregunta\n",
    "def iniciar_conversacion_proactiva(\n",
    "    generar_audio: bool = True,\n",
    "    ruta_audio_respuesta: str = \"respuestas/proactivo_inicio.mp3\",\n",
    "    voz: str = \"alloy\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Inicia una conversación proactiva:\n",
    "    - genera una primera pregunta amigable,\n",
    "    - la guarda en el historial de conversación,\n",
    "    - opcionalmente genera audio.\n",
    "    \"\"\"\n",
    "\n",
    "    global CONVERSACION_PROACTIVA\n",
    "    CONVERSACION_PROACTIVA = []  # reseteamos la conversación\n",
    "\n",
    "    proactivo = generar_pregunta_proactiva()\n",
    "    pregunta_texto = proactivo.get(\"texto\", \"¿Te gustaría contarme algo lindo de tu vida?\")\n",
    "    tipo = proactivo.get(\"tipo\", \"compañia\")\n",
    "\n",
    "    # Guardamos en historial como mensaje del asistente\n",
    "    CONVERSACION_PROACTIVA.append({\"role\": \"assistant\", \"content\": pregunta_texto})\n",
    "\n",
    "    print(\"\\n=== INICIO CONVERSACIÓN PROACTIVA ===\")\n",
    "    print(\"Tipo:\", tipo)\n",
    "    print(\"Pregunta:\", pregunta_texto)\n",
    "\n",
    "    ruta_audio = None\n",
    "    if generar_audio:\n",
    "        ruta = Path(ruta_audio_respuesta)\n",
    "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ruta_audio = texto_a_audio(\n",
    "            texto=pregunta_texto,\n",
    "            ruta_salida=str(ruta),\n",
    "            voz=voz,\n",
    "        )\n",
    "        print(\"Audio inicial generado en:\", ruta_audio)\n",
    "\n",
    "    return {\n",
    "        \"tipo\": tipo,\n",
    "        \"pregunta_texto\": pregunta_texto,\n",
    "        \"ruta_audio\": ruta_audio,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ab39c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuar_conversacion_proactiva(\n",
    "    audio_path: str,\n",
    "    generar_audio: bool = True,\n",
    "    ruta_audio_respuesta: str = \"respuestas/proactivo_turno.mp3\",\n",
    "    voz: str = \"alloy\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Usa la respuesta de la persona (audio) para seguir la conversación:\n",
    "    - transcribe la respuesta,\n",
    "    - actualiza perfil si hay info nueva,\n",
    "    - extrae recuerdos/tareas y los guarda en memoria,\n",
    "    - genera una respuesta amigable de conversación,\n",
    "    - opcionalmente la convierte a audio.\n",
    "    \"\"\"\n",
    "\n",
    "    global CONVERSACION_PROACTIVA\n",
    "\n",
    "    print(f\"\\n=== CONTINUAR CONVERSACIÓN PROACTIVA: {audio_path} ===\")\n",
    "    texto_usuario = transcribe(audio_path)\n",
    "    print(\"\\nRESPUESTA (transcripción):\")\n",
    "    print(texto_usuario)\n",
    "\n",
    "    # 1) Actualizar perfil si hay info relevante\n",
    "    procesar_texto_para_perfil(texto_usuario)\n",
    "\n",
    "    # 2) Extraer recuerdos/tareas y guardarlos en memoria (como modo captura)\n",
    "    items = procesar_memoria_con_chatgpt(texto_usuario)\n",
    "    if items:\n",
    "        agregar_items_a_memoria(items, texto_usuario)\n",
    "        print(f\"\\nSe guardaron {len(items)} ítems nuevos en la memoria.\")\n",
    "\n",
    "    # 3) Agregar turno de usuario al historial de conversación\n",
    "    CONVERSACION_PROACTIVA.append({\"role\": \"user\", \"content\": texto_usuario})\n",
    "\n",
    "    # 4) Construir prompt para respuesta conversacional\n",
    "    memoria = cargar_memoria()\n",
    "    contexto_memorias = json.dumps(memoria[-30:], ensure_ascii=False, indent=2)\n",
    "\n",
    "    base_instructions = \"\"\"\n",
    "Eres un asistente de MEMORIA y COMPAÑÍA para una persona mayor.\n",
    "\n",
    "Tu rol en este modo es sostener una conversación amable, breve y significativa.\n",
    "Debes:\n",
    "- Escuchar lo que la persona cuenta.\n",
    "- Validar sus emociones y recuerdos de forma cálida.\n",
    "- Hacer, si corresponde, UNA sola pregunta de seguimiento suave (no interrogatorio).\n",
    "- Puedes usar la información de las MEMORIAS (JSON) para recordar cosas que la persona ha mencionado antes.\n",
    "\n",
    "No intentes corregir detalles de memoria a menos que sean críticos.\n",
    "No des consejos médicos ni diagnósticos: si surge algo de salud, responde de forma empática\n",
    "y sugiere que lo converse con su médico o su familia.\n",
    "\n",
    "Forma de responder:\n",
    "- En español.\n",
    "- Máximo 2 frases.\n",
    "- Tono cálido, cercano y claro, pensado para ser escuchado en voz alta.\n",
    "- Puedes usar el nombre de la persona si lo sabes.\n",
    "\"\"\"\n",
    "\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "\n",
    "    # Armamos el historial como mensajes para el modelo\n",
    "    mensajes = [{\"role\": \"system\", \"content\": system_msg}]\n",
    "    for turno in CONVERSACION_PROACTIVA:\n",
    "        mensajes.append(turno)\n",
    "\n",
    "    # Incluimos las memorias como contexto en el último mensaje del usuario\n",
    "    mensajes.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            CONVERSACION_PROACTIVA[-1][\"content\"]\n",
    "            + \"\\n\\n(Para tu contexto, aquí hay algunas memorias recientes en JSON:\"\n",
    "            + f\"\\n{contexto_memorias}\\n)\"\n",
    "        )\n",
    "    })\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.6,\n",
    "        messages=mensajes,\n",
    "    )\n",
    "\n",
    "    respuesta_texto = completion.choices[0].message.content.strip()\n",
    "    print(\"\\nRESPUESTA DEL AGENTE (conversación):\")\n",
    "    print(respuesta_texto)\n",
    "\n",
    "    # Guardamos turno del asistente en el historial\n",
    "    CONVERSACION_PROACTIVA.append({\"role\": \"assistant\", \"content\": respuesta_texto})\n",
    "\n",
    "    ruta_audio = None\n",
    "    if generar_audio:\n",
    "        ruta = Path(ruta_audio_respuesta)\n",
    "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ruta_audio = texto_a_audio(\n",
    "            texto=respuesta_texto,\n",
    "            ruta_salida=str(ruta),\n",
    "            voz=voz,\n",
    "        )\n",
    "        print(\"Audio de respuesta generado en:\", ruta_audio)\n",
    "\n",
    "    return {\n",
    "        \"texto_respuesta\": respuesta_texto,\n",
    "        \"ruta_audio_respuesta\": ruta_audio,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc128173",
   "metadata": {},
   "source": [
    "#### Ejemplo de uso conversacion proactiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da2d6b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIO CONVERSACIÓN PROACTIVA ===\n",
      "Tipo: memoria_evento\n",
      "Pregunta: ¿Qué planes tienes para el cumpleaños de tu hija Antonia el lunes 24?\n",
      "Audio inicial generado en: respuestas/proactivo_inicio.mp3\n",
      "¿Qué planes tienes para el cumpleaños de tu hija Antonia el lunes 24?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "inicio = iniciar_conversacion_proactiva()\n",
    "print(inicio[\"pregunta_texto\"])\n",
    "# Reproducir inicio[\"ruta_audio\"] en tu UI / reproductor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c0b9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONTINUAR CONVERSACIÓN PROACTIVA: audios/respuesta_proactiva_1.m4a ===\n",
      "\n",
      "RESPUESTA (transcripción):\n",
      "Quiero ir y estar con mis nietos. Quiero comer la torta caluga de mi nieta, Francisca, y volver temprano. Estoy un poco cansada.\n",
      "Perfil actualizado con:\n",
      "{\n",
      "  \"familia\": [\n",
      "    {\n",
      "      \"nombre\": \"Francisca\",\n",
      "      \"relacion\": \"nieta\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Se guardaron 4 ítems nuevos en la memoria.\n",
      "\n",
      "RESPUESTA DEL AGENTE (conversación):\n",
      "Es bonito que quieras estar con tus nietos y disfrutar de la torta caluga de Francisca, aunque te sientas un poco cansada. ¿Qué es lo que más te gusta de pasar tiempo con ellos?\n",
      "Audio de respuesta generado en: respuestas/proactivo_turno.mp3\n",
      "Es bonito que quieras estar con tus nietos y disfrutar de la torta caluga de Francisca, aunque te sientas un poco cansada. ¿Qué es lo que más te gusta de pasar tiempo con ellos?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "turno1 = continuar_conversacion_proactiva(\"audios/respuesta_proactiva_1.m4a\")\n",
    "print(turno1[\"texto_respuesta\"])\n",
    "# Reproducir turno1[\"ruta_audio_respuesta\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "502e91fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONTINUAR CONVERSACIÓN PROACTIVA: audios/respuesta_proactiva_2.m4a ===\n",
      "\n",
      "RESPUESTA (transcripción):\n",
      "Me gusta estar con ellos porque son tan llenos de cosas, son tan vivos, me llenan de buenas recuerdas.\n",
      "No se detectó información de perfil en este texto.\n",
      "\n",
      "RESPUESTA DEL AGENTE (conversación):\n",
      "Es hermoso que tus nietos te traigan tantos buenos recuerdos y alegría. ¿Hay alguna anécdota especial que te gustaría compartir de esos momentos juntos?\n",
      "Audio de respuesta generado en: respuestas/proactivo_turno.mp3\n",
      "Es hermoso que tus nietos te traigan tantos buenos recuerdos y alegría. ¿Hay alguna anécdota especial que te gustaría compartir de esos momentos juntos?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "turno2 = continuar_conversacion_proactiva(\"audios/respuesta_proactiva_2.m4a\")\n",
    "print(turno2[\"texto_respuesta\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79eedf",
   "metadata": {},
   "source": [
    "## NPS Diario (mini preguntas diarias para ir evaluando el estado de la persona, algo como \"del 1 al 5, cómo te sientes hoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f716d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iniciar_nps_diario(\n",
    "    generar_audio: bool = True,\n",
    "    ruta_audio_pregunta: str = \"respuestas/nps_pregunta.mp3\",\n",
    "    voz: str = \"alloy\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Hace la pregunta del 'NPS del día' a la persona:\n",
    "    Del 1 al 5, ¿cómo te sientes hoy?\n",
    "    Devuelve el texto de la pregunta y la ruta del audio (si se genera).\n",
    "    \"\"\"\n",
    "\n",
    "    # Puedes personalizar esto después usando el perfil\n",
    "    pregunta_texto = (\n",
    "        \"Del 1 al 5, ¿cómo te sientes hoy, donde 1 es muy mal y 5 es muy bien? \"\n",
    "        \"Si quieres, también cuéntame brevemente por qué.\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== NPS DIARIO: PREGUNTA ===\")\n",
    "    print(pregunta_texto)\n",
    "\n",
    "    ruta_audio = None\n",
    "    if generar_audio:\n",
    "        ruta = Path(ruta_audio_pregunta)\n",
    "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ruta_audio = texto_a_audio(\n",
    "            texto=pregunta_texto,\n",
    "            ruta_salida=str(ruta),\n",
    "            voz=voz,\n",
    "        )\n",
    "        print(\"Audio de la pregunta generado en:\", ruta_audio)\n",
    "\n",
    "    return {\n",
    "        \"pregunta_texto\": pregunta_texto,\n",
    "        \"ruta_audio_pregunta\": ruta_audio,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "796feba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_nps_desde_texto(texto: str) -> dict:\n",
    "    \"\"\"\n",
    "    Usa el LLM para extraer una puntuación 1-5 de bienestar diario,\n",
    "    más un comentario resumen y un flag de alerta.\n",
    "    \"\"\"\n",
    "\n",
    "    base_instructions = \"\"\"\n",
    "Eres un asistente que analiza cómo se siente una persona mayor hoy.\n",
    "\n",
    "Recibirás la respuesta de la persona a una pregunta del tipo:\n",
    "\"Del 1 al 5, ¿cómo te sientes hoy, donde 1 es muy mal y 5 es muy bien?\"\n",
    "\n",
    "Tu tarea es devolver:\n",
    "\n",
    "- \"puntuacion\": un número entero entre 1 y 5 según lo que dice la persona.\n",
    "  * 1 = muy mal, 2 = mal, 3 = más o menos, 4 = bien, 5 = muy bien\n",
    "- \"comentario\": una breve frase en español resumiendo cómo se siente\n",
    "  (puede basarse en sus propias palabras).\n",
    "- \"alerta\": true/false\n",
    "  * true si la persona se siente mal (puntuacion <= 2) o menciona cosas preocupantes\n",
    "    (dolor fuerte, mucha tristeza, soledad extrema, ideas negativas, etc.).\n",
    "  * false si la persona se siente principalmente bien o estable.\n",
    "\n",
    "Si la persona no da un número claro, intenta inferirlo de lo que dice.\n",
    "Si no puedes inferir nada, usa puntuacion = 3 y alerta = false.\n",
    "\n",
    "FORMATO DE SALIDA (JSON):\n",
    "Devuelve SIEMPRE algo como:\n",
    "\n",
    "{\n",
    "  \"puntuacion\": 3,\n",
    "  \"comentario\": \"Me siento más o menos, un poco cansada\",\n",
    "  \"alerta\": false\n",
    "}\n",
    "\n",
    "No añadas texto fuera del JSON.\n",
    "\"\"\"\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": texto},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw = completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"No se pudo parsear JSON en extraer_nps_desde_texto. Respuesta cruda:\")\n",
    "        print(raw)\n",
    "        raise\n",
    "\n",
    "    # Defaults por seguridad\n",
    "    if \"puntuacion\" not in data or not isinstance(data[\"puntuacion\"], int):\n",
    "        data[\"puntuacion\"] = 3\n",
    "    if \"comentario\" not in data:\n",
    "        data[\"comentario\"] = \"\"\n",
    "    if \"alerta\" not in data:\n",
    "        data[\"alerta\"] = False\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec764bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_nps_en_memoria(texto_original: str, nps_info: dict):\n",
    "    \"\"\"\n",
    "    Guarda el resultado del NPS diario en memoria.json\n",
    "    como un item de tipo 'nps_dia'.\n",
    "    \"\"\"\n",
    "    memoria = cargar_memoria()\n",
    "    next_id = (memoria[-1][\"id\"] + 1) if memoria else 1\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    fecha_hoy = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    registro = {\n",
    "        \"id\": next_id,\n",
    "        \"timestamp_guardado\": timestamp,\n",
    "        \"origen\": \"nps\",\n",
    "        \"texto_original\": texto_original,\n",
    "        \"item\": {\n",
    "            \"tipo\": \"nps_dia\",\n",
    "            \"fecha\": fecha_hoy,\n",
    "            \"puntuacion\": nps_info.get(\"puntuacion\"),\n",
    "            \"comentario\": nps_info.get(\"comentario\"),\n",
    "            \"alerta\": nps_info.get(\"alerta\"),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    memoria.append(registro)\n",
    "    guardar_memoria(memoria)\n",
    "\n",
    "    return registro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67c3692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_respuesta_nps(\n",
    "    audio_path: str,\n",
    "    generar_audio: bool = True,\n",
    "    ruta_audio_respuesta: str = \"respuestas/nps_respuesta.mp3\",\n",
    "    voz: str = \"alloy\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Procesa la respuesta de la persona al NPS diario:\n",
    "    - transcribe el audio,\n",
    "    - actualiza perfil si hay info,\n",
    "    - extrae puntuación 1-5 + comentario + alerta,\n",
    "    - guarda el registro en memoria,\n",
    "    - genera una respuesta amable (texto + audio opcional).\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n=== NPS DIARIO: RESPUESTA DESDE {audio_path} ===\")\n",
    "    texto = transcribe(audio_path)\n",
    "    print(\"\\nTRANSCRIPCIÓN DE LA RESPUESTA:\")\n",
    "    print(texto)\n",
    "\n",
    "    # Por si en la respuesta menciona datos de perfil\n",
    "    procesar_texto_para_perfil(texto)\n",
    "\n",
    "    nps_info = extraer_nps_desde_texto(texto)\n",
    "    print(\"\\nNPS EXTRAÍDO:\")\n",
    "    print(nps_info)\n",
    "\n",
    "    registro = guardar_nps_en_memoria(texto, nps_info)\n",
    "    print(\"\\nRegistro guardado en memoria:\")\n",
    "    print(json.dumps(registro, ensure_ascii=False, indent=2))\n",
    "\n",
    "    puntuacion = nps_info[\"puntuacion\"]\n",
    "    alerta = nps_info[\"alerta\"]\n",
    "\n",
    "    # Respuesta simple según la puntuación\n",
    "    if puntuacion >= 4:\n",
    "        respuesta_texto = (\n",
    "            f\"Me alegra mucho que hoy te sientas con un {puntuacion}. \"\n",
    "            \"Gracias por contármelo.\"\n",
    "        )\n",
    "    elif puntuacion == 3:\n",
    "        respuesta_texto = (\n",
    "            \"Entiendo, hoy te sientes más o menos. \"\n",
    "            \"Gracias por compartirlo conmigo.\"\n",
    "        )\n",
    "    else:  # 1 o 2\n",
    "        respuesta_texto = (\n",
    "            \"Siento que hoy no te sientas tan bien. \"\n",
    "            \"Voy a guardar esto para que tu familia pueda ayudarte si es necesario.\"\n",
    "        )\n",
    "\n",
    "    if alerta:\n",
    "        # Puedes usar esto para levantar una alerta en tu UI en el futuro\n",
    "        print(\"\\n⚠️ ALERTA: NPS bajo o situación preocupante detectada.\")\n",
    "\n",
    "    ruta_audio = None\n",
    "    if generar_audio:\n",
    "        ruta = Path(ruta_audio_respuesta)\n",
    "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ruta_audio = texto_a_audio(\n",
    "            texto=respuesta_texto,\n",
    "            ruta_salida=str(ruta),\n",
    "            voz=voz,\n",
    "        )\n",
    "        print(\"Audio de respuesta NPS generado en:\", ruta_audio)\n",
    "\n",
    "    return {\n",
    "        \"texto_respuesta\": respuesta_texto,\n",
    "        \"ruta_audio_respuesta\": ruta_audio,\n",
    "        \"nps_info\": nps_info,\n",
    "        \"registro_memoria\": registro,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "397b9ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NPS DIARIO: PREGUNTA ===\n",
      "Del 1 al 5, ¿cómo te sientes hoy, donde 1 es muy mal y 5 es muy bien? Si quieres, también cuéntame brevemente por qué.\n",
      "Audio de la pregunta generado en: respuestas/nps_pregunta.mp3\n",
      "Del 1 al 5, ¿cómo te sientes hoy, donde 1 es muy mal y 5 es muy bien? Si quieres, también cuéntame brevemente por qué.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "nps_q = iniciar_nps_diario()\n",
    "print(nps_q[\"pregunta_texto\"])\n",
    "# reproduces nps_q[\"ruta_audio_pregunta\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c83b2171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NPS DIARIO: RESPUESTA DESDE audios/nps_respuesta_2025-11-22.m4a ===\n",
      "\n",
      "TRANSCRIPCIÓN DE LA RESPUESTA:\n",
      "La verdad es que hoy día le pondría un 4. Ha sido un buen día, pero siento una leve molestia en mi rodilla.\n",
      "No se detectó información de perfil en este texto.\n",
      "\n",
      "NPS EXTRAÍDO:\n",
      "{'puntuacion': 4, 'comentario': 'Ha sido un buen día, aunque tengo una leve molestia en la rodilla.', 'alerta': False}\n",
      "\n",
      "Registro guardado en memoria:\n",
      "{\n",
      "  \"id\": 17,\n",
      "  \"timestamp_guardado\": \"2025-11-22T16:09:47.124581\",\n",
      "  \"origen\": \"nps\",\n",
      "  \"texto_original\": \"La verdad es que hoy día le pondría un 4. Ha sido un buen día, pero siento una leve molestia en mi rodilla.\",\n",
      "  \"item\": {\n",
      "    \"tipo\": \"nps_dia\",\n",
      "    \"fecha\": \"2025-11-22\",\n",
      "    \"puntuacion\": 4,\n",
      "    \"comentario\": \"Ha sido un buen día, aunque tengo una leve molestia en la rodilla.\",\n",
      "    \"alerta\": false\n",
      "  }\n",
      "}\n",
      "Audio de respuesta NPS generado en: respuestas/nps_respuesta.mp3\n",
      "Me alegra mucho que hoy te sientas con un 4. Gracias por contármelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/0hz0x2lj64g6xdgr7dxjf2xh0000gn/T/ipykernel_6352/2117199918.py:20: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(speech_file_path)\n"
     ]
    }
   ],
   "source": [
    "res_nps = procesar_respuesta_nps(\"audios/nps_respuesta_2025-11-22.m4a\")\n",
    "print(res_nps[\"texto_respuesta\"])\n",
    "# reproduces res_nps[\"ruta_audio_respuesta\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b793e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generar_resumen_diario(fecha: str = None, max_items: int = 200) -> str:\n",
    "    \"\"\"\n",
    "    Genera un resumen diario muy breve de cómo estuvo la persona,\n",
    "    usando la memoria y el perfil (nombre, etc.).\n",
    "\n",
    "    - fecha: string \"YYYY-MM-DD\". Si es None, se usa la fecha de hoy.\n",
    "    - max_items: cuántos registros recientes de memoria considerar como máximo.\n",
    "\n",
    "    Devuelve un TEXTO en español, pensado para enviar por WhatsApp o mostrar en un panel.\n",
    "    \"\"\"\n",
    "\n",
    "    memoria = cargar_memoria()\n",
    "    recientes = memoria[-max_items:]\n",
    "\n",
    "    # Fecha objetivo\n",
    "    if fecha is None:\n",
    "        fecha_obj = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        fecha_obj = fecha\n",
    "\n",
    "    contexto_memorias = json.dumps(recientes, ensure_ascii=False, indent=2)\n",
    "\n",
    "    base_instructions = f\"\"\"\n",
    "Eres un asistente de MEMORIA y ACOMPAÑAMIENTO para una persona mayor.\n",
    "\n",
    "Tu tarea es crear un RESUMEN DIARIO MUY BREVE para la familia o cuidadores,\n",
    "sobre cómo estuvo la persona en la fecha indicada.\n",
    "\n",
    "La FECHA objetivo del resumen es: {fecha_obj}\n",
    "\n",
    "IMPORTANTE:\n",
    "- En el contexto del usuario (que verás en el mensaje de sistema) tienes su nombre.\n",
    "- Usa ese nombre para referirte a ella, por ejemplo \"María\" o \"tu mamá María\".\n",
    "- Evita frases impersonales como \"la persona\", \"el usuario\", etc.\n",
    "\n",
    "Tendrás una lista de MEMORIAS en JSON (recientes), donde cada registro tiene:\n",
    "- id\n",
    "- timestamp_guardado\n",
    "- origen (p.ej. \"audio\", \"documento_medico\", \"nps\")\n",
    "- texto_original\n",
    "- item: con campos como:\n",
    "    * tipo: \"Evento\", \"Recuerdo\", \"receta\", \"examen\", \"nps_dia\", \"Ninguno\", etc.\n",
    "    * fecha: string \"YYYY-MM-DD\" si aplica.\n",
    "    * hora\n",
    "    * descripcion\n",
    "    * clasificacion\n",
    "    * responsable_requerido\n",
    "    * personas\n",
    "    * lugar\n",
    "    * En el caso de nps_dia:\n",
    "        - tipo = \"nps_dia\"\n",
    "        - fecha = \"YYYY-MM-DD\"\n",
    "        - puntuacion: 1 a 5\n",
    "        - comentario: texto\n",
    "        - alerta: true/false\n",
    "\n",
    "CÉNTRATE en lo siguiente para la FECHA objetivo:\n",
    "\n",
    "1. Estado de ánimo del día (NPS)\n",
    "   - Si hay registros tipo \"nps_dia\" para esa fecha:\n",
    "        * menciona la puntuación (1–5), mencionando la escala (por ejemplo un 4 de 5)\n",
    "        * resume en pocas palabras el comentario\n",
    "        * si alerta = true, menciónalo como algo a tener en cuenta.\n",
    "   - Si no hay NPS para ese día, puedes decir que no hay registro de cómo se sintió hoy.\n",
    "\n",
    "2. Citas y eventos del día\n",
    "   - Revisa items tipo \"Evento\" relacionados con esa fecha.\n",
    "   - Indica brevemente si tenía citas médicas u otros compromisos importantes.\n",
    "   - Si no hay información sobre asistencia, sé neutro: no inventes.\n",
    "\n",
    "3. Interacciones / cosas destacadas\n",
    "   - Si hay recuerdos o eventos con familia o actividades relevantes, menciona 1 idea clave\n",
    "     (por ejemplo, \"conversó sobre sus nietos\" o \"recordó un momento feliz\").\n",
    "\n",
    "4. Alertas\n",
    "   - Si la puntuación es baja (<= 2) o hay comentarios preocupantes, dilo explícitamente\n",
    "     en UNA frase corta, para que la familia ponga atención.\n",
    "\n",
    "FORMA DE RESPONDER:\n",
    "- Responde en español.\n",
    "- Usa SOLO 2 o 3 frases cortas.\n",
    "- Tono cercano y claro, pensado para que se lea rápido (WhatsApp / resumen).\n",
    "- Dirígete a la familia/cuidadores, usando el nombre de la persona cuando tenga sentido.\n",
    "- NO incluyas JSON, solo texto natural.\n",
    "\"\"\"\n",
    "\n",
    "    system_msg = construir_system_con_perfil(base_instructions)\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "MEMORIAS (JSON) RECENTES:\n",
    "{contexto_memorias}\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    resumen = completion.choices[0].message.content.strip()\n",
    "    return resumen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bb8e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoy, María tuvo un buen día, con una puntuación de 4 de 5 en su estado de ánimo, aunque mencionó una leve molestia en la rodilla. Recordó que el lunes 24 es el cumpleaños de su hija Antonia y expresó su deseo de estar con sus nietos y comer la torta caluga de Francisca. No hay alertas preocupantes, pero es bueno estar atentos a su molestia.\n"
     ]
    }
   ],
   "source": [
    "resumen_hoy = generar_resumen_diario() #para una fecha específica:  generar_resumen_diario(\"2025-11-21\")\n",
    "print(resumen_hoy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe677bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
